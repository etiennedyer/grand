
**Graph neural diffusion** </br>
This repo contains the work I've done around [GRAND](https://arxiv.org/abs/2106.10934) by Chamberlain et al. The final report is [here](GRAND-EÃÅtienne-final.pdf), and the code for the main analysis concerning GRAND's resistance oversmoothing is [here](oversmoothing_analysis.py). In the end, my numerics on the CORA dataset didn't really support the authors' claim that GRAND is resistant to oversmoothing, though the architecture did have increased numerical stability / lower variance across runs. I still really enjoyed the project, got more comfortable with numerical analysis which was long overdue, and learned some PyTorch. I still stand by my impression that models with nice theoretical properties do not tend to be breakthrough models. 
